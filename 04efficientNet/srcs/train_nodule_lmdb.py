#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
V73 ç”²çŠ¶è…ºç»“èŠ‚ç‰¹å¾CNNæ¨¡å‹è®­ç»ƒè„šæœ¬ (EfficientNet-B0 å¤šä»»åŠ¡ç‰ˆ)

v73: verify

v70: all the dataset balanced with fna/surgery_0924 and tr1-3
     all_matched_sops_ds_v3_0924.csv
     + none_single_tr13.csv
     = all_matched_sops_ds_v3_with_tr13_0926.csv

V60: OOF_p_true_threshold=0.5
V61: OOF_p_true_threshold=0.2
V64: OOF_p_true_threshold=0.1, image_index_threshold=16

v66: OOF_p_true_threshold=0.1, image_index_threshold=16
     dataset -> sop_fna_nodules_with_path_v3_with_OOF_suspect.csv
     bom_weight: 0.9, ti_rads:0.5, feature:0.1 x 5

v67: OOF_p_true_threshold=0.1, image_index_threshold=16
    dataset -> sop_fna_nodules_with_path_v3_with_OOF_suspect.csv
    dropout=0.5

v68: OOF_p_true_threshold=0.3, image_index_threshold=16
    dataset -> sop_fna_nodules_with_path_v3_with_OOF_suspect.csv
    verify -> 0809_v3
    dropout=0.5

v68: OOF_p_true_threshold=0.5, image_index_threshold=16
    dataset -> sop_fna_nodules_with_path_v3_with_OOF_suspect.csv
    verify -> 0809_v3
    dropout=0.6

V64 æ ¸å¿ƒç‰¹æ€§:
1. å¤šä»»åŠ¡å­¦ä¹ :
   - ä¸»è¦ä»»åŠ¡: BOMåˆ†ç±» (è‰¯æ¶æ€§)
   - è¾…åŠ©ä»»åŠ¡: TI-RADSåˆ†ç±» (1-5çº§), ä»¥åŠ5ä¸ªè¶…å£°å¾è±¡åˆ†ç±» (composition, echo, foci, margin, shape)
2. ç»Ÿä¸€ç‰¹å¾æ˜ å°„:
   - æ‰€æœ‰åˆ†ç±»ä»»åŠ¡çš„æ ‡ç­¾å’Œåºå·å‡ç”± `core/utils/all_features_mapping_numer_v4.json` å®šä¹‰
   - æ˜ å°„è¡¨ä¼šåµŒå…¥åˆ°æ¨¡å‹ä¸­ï¼Œä¾¿äºæ¨ç†æ—¶ç›´æ¥è°ƒç”¨
3. å¤æ‚çš„ç­›é€‰ç­–ç•¥:
   - å›¾åƒå­˜åœ¨æ€§æ£€æŸ¥
   - æ ¹æ®OOFé¢„æµ‹å‰”é™¤ç–‘ä¼¼é”™æ ‡æ ·æœ¬ (å½“OOF_p_true_threshold>0æ—¶: p_true < threshold & pred != true)
   - å‰”é™¤æŒ‡å®šæœˆä»½æ•°æ® (2024å¹´8-9æœˆ)ï¼Œé˜²æ­¢æ•°æ®æ³„éœ²
   - å‰”é™¤TI-RADS=6çš„æ ·æœ¬ (å·²ç—…ç†è¯å®çš„æ¶æ€§)
   - å‰”é™¤image_index > 16çš„æ•°æ® (sop_uidä¸­ä»¥'.'åˆ†éš”çš„å€’æ•°ç¬¬äºŒæ®µ)
4. æŸå¤±æƒé‡:
   - bom_weight: 0.7
   - å…¶ä»–6ä¸ªè¾…åŠ©ä»»åŠ¡æƒé‡å„0.05
5. ç‹¬ç«‹éªŒè¯é›†:
   - å®šæœŸ (æ¯5ä¸ªepoch) åœ¨ç‹¬ç«‹çš„éªŒè¯é›†ä¸Šè¯„ä¼°æ€§èƒ½ï¼Œç›‘æ§æ³›åŒ–èƒ½åŠ›
"""

import os
import sys
import json
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import GroupShuffleSplit
from torchvision import models, transforms
from PIL import Image
from tqdm import tqdm
from sklearn.metrics import roc_auc_score, confusion_matrix, mean_squared_error
from torch.utils.tensorboard import SummaryWriter  # ä¸´æ—¶ç¦ç”¨
import warnings
import matplotlib.pyplot as plt
import random
import re
from datetime import datetime
import io
import sys

warnings.filterwarnings('ignore')

# =============================================================================
# é…ç½®ç®¡ç† - V64 é…ç½®é¡¹ç»Ÿä¸€ç®¡ç†
# =============================================================================
CONFIG = {
    # æ•°æ®é›†é…ç½®
    'sop4_data': 'data/dataset_table/train/all_matched_sops_ds_v3_with_tr13_0926_with_OOF_suspect.csv',
    'verify_data': 'data/dataset_table/val/all_verify_sop_with_predictions.csv',
    'image_root': 'data/dataset_images/2nodule_images',
    'verify_root': 'data/dataset_images/2nodule_images',
    'feature_mapping_file': 'utils/all_features_mapping_numer_v4.json',
    
    # LMDBé…ç½® (é«˜é€ŸI/O)
    'use_lmdb': True,  # æ˜¯å¦ä½¿ç”¨LMDBåŠ é€Ÿæ•°æ®åŠ è½½
    'train_lmdb_path': 'data/dataset_lmdb/train_lmdb',
    'val_lmdb_path': 'data/dataset_lmdb/val_lmdb',
    'verify_lmdb_path': 'data/dataset_lmdb/verify_lmdb',

    # æ¨¡å‹é…ç½®
    'model_name': 'v75',
    'output_dir': 'data/models/nodule_feature_cnn_v75',
    'tensorboard_dir': 'runs/nodule_feature_cnn_v75',
    'dropout_rate': 0.4,

    # è®­ç»ƒé…ç½®
    'batch_size': 256,  # å¢å¤§batchè®©æ¯å¡è®¡ç®—é‡æ›´å¤š
    'num_epochs': 50,
    'learning_rate': 5e-5,
    'weight_decay': 1e-2,
    'early_stop_patience': 10,
    'max_grad_norm': 1.0,
    'verify_epoch_interval': 5,

    # æ•°æ®ç­›é€‰é…ç½®
    'OOF_p_true_threshold': 0.2,
    'image_index_threshold': 16,
    'exclude_months': ['202408', '202409'],
    'exclude_ti_rads': [6],

    # æŸå¤±æƒé‡é…ç½® (æ€»å’Œåº”ä¸º1.0)
    'loss_weights': {
        'bom': 0.9,
        'ti_rads': 0.05,
        'composition': 0.01,
        'echo': 0.01,
        'foci': 0.01,
        'margin': 0.01,
        'shape': 0.01
    },

    # æ•°æ®åˆ’åˆ†é…ç½®
    'test_size': 0.2,
    'random_state': 42,
    'num_workers': 8,  # å•GPUé…åˆLMDBé«˜é€Ÿè¯»å–
    
    # å¤šGPUé…ç½®
    'use_multi_gpu': False,  # å•å¡è®­ç»ƒï¼ˆå°æ¨¡å‹æ•ˆç‡æœ€é«˜ï¼‰
    'gpu_ids': [0],  # å•å¡
}

# =============================================================================
# æ—¥å¿—è®°å½•ç±»
# =============================================================================

class TrainingLogger:
    """è®­ç»ƒæ—¥å¿—è®°å½•å™¨ - åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶"""
    def __init__(self, log_file_path):
        self.log_file_path = log_file_path
        self.log_buffer = []
        self.best_epoch_info = {}
        self.final_verify_info = {}

    def log(self, message):
        """è®°å½•æ¶ˆæ¯åˆ°ç¼“å†²åŒºå’Œæ§åˆ¶å°"""
        print(message)
        self.log_buffer.append(message)

    def log_best_epoch(self, epoch, train_metrics, val_metrics):
        """è®°å½•æœ€ä½³epochä¿¡æ¯"""
        self.best_epoch_info = {
            'epoch': epoch + 1,
            'train_metrics': train_metrics.copy(),
            'val_metrics': val_metrics.copy()
        }

    def log_final_verify(self, verify_metrics):
        """è®°å½•æœ€ç»ˆéªŒè¯ä¿¡æ¯"""
        self.final_verify_info = verify_metrics.copy()

    def save_training_summary(self, config, best_auc, total_epochs):
        """ä¿å­˜è®­ç»ƒæ€»ç»“åˆ°æ–‡ä»¶"""
        try:
            with open(self.log_file_path, 'w', encoding='utf-8') as f:
                f.write("=" * 80 + "\n")
                f.write(f"V64 ç”²çŠ¶è…ºç»“èŠ‚ç‰¹å¾CNNæ¨¡å‹è®­ç»ƒæŠ¥å‘Š\n")
                f.write(f"è®­ç»ƒæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write("=" * 80 + "\n\n")

                # 1. æ¨¡å‹é…ç½®ä¿¡æ¯
                f.write("ğŸ“‹ æ¨¡å‹é…ç½®ä¿¡æ¯:\n")
                f.write(f"  æ¨¡å‹ç‰ˆæœ¬: {config['model_name']}\n")
                f.write(f"  æ¨¡å‹æ¶æ„: EfficientNet-B0 å¤šä»»åŠ¡ç‰ˆ\n")
                f.write(f"  è¾“å‡ºç›®å½•: {config['output_dir']}\n")
                f.write(f"  è®­ç»ƒå›¾åƒæ ¹ç›®å½•: {config['image_root']}\n")
                if 'verify_root' in config:
                    f.write(f"  éªŒè¯å›¾åƒæ ¹ç›®å½•: {config['verify_root']}\n")
                else:
                    f.write(f"  éªŒè¯å›¾åƒæ ¹ç›®å½•: {config['image_root']} (ä¸è®­ç»ƒç›¸åŒ)\n")
                f.write(f"  æ‰¹æ¬¡å¤§å°: {config['batch_size']}\n")
                f.write(f"  å­¦ä¹ ç‡: {config['learning_rate']}\n")
                f.write(f"  æƒé‡è¡°å‡: {config['weight_decay']}\n")
                f.write(f"  æ—©åœè½®æ•°: {config['early_stop_patience']}\n")
                f.write(f"  Dropoutç‡: {config['dropout_rate']}\n\n")

                # 2. æ•°æ®ç­›é€‰é…ç½®
                f.write("ğŸ” æ•°æ®ç­›é€‰é…ç½®:\n")
                oof_threshold = config['OOF_p_true_threshold']
                if oof_threshold == 0:
                    f.write(f"  OOF_p_true_threshold: {oof_threshold} (è·³è¿‡OOFç­›é€‰)\n")
                else:
                    f.write(f"  OOF_p_true_threshold: {oof_threshold}\n")
                f.write(f"  image_index_threshold: {config['image_index_threshold']}\n")
                f.write(f"  æ’é™¤æœˆä»½: {config['exclude_months']}\n")
                f.write(f"  æ’é™¤TI-RADS: {config['exclude_ti_rads']}\n\n")

                # 3. æŸå¤±æƒé‡é…ç½®
                f.write("âš–ï¸ æŸå¤±æƒé‡é…ç½®:\n")
                for task, weight in config['loss_weights'].items():
                    f.write(f"  {task.capitalize():<12}: {weight}\n")
                f.write("\n")

                # 4. è®­ç»ƒç»“æœæ¦‚è¦
                f.write("ğŸ¯ è®­ç»ƒç»“æœæ¦‚è¦:\n")
                f.write(f"  æ€»è®­ç»ƒè½®æ•°: {total_epochs}\n")
                f.write(f"  æœ€ä½³éªŒè¯AUC: {best_auc:.4f}\n")
                if self.best_epoch_info:
                    f.write(f"  æœ€ä½³epoch: {self.best_epoch_info['epoch']}\n")
                f.write("\n")

                # 5. æœ€ä½³epochè¯¦ç»†æŒ‡æ ‡
                if self.best_epoch_info:
                    f.write("ğŸ† æœ€ä½³Epochè¯¦ç»†æŒ‡æ ‡:\n")
                    f.write(f"  Epoch: {self.best_epoch_info['epoch']}\n")

                    train_metrics = self.best_epoch_info['train_metrics']
                    val_metrics = self.best_epoch_info['val_metrics']

                    f.write("  è®­ç»ƒé›†æŒ‡æ ‡:\n")
                    f.write(f"    BOM AUC: {train_metrics.get('bom_auc', 0):.4f}\n")
                    f.write(f"    BOM Accuracy: {train_metrics.get('bom_accuracy', 0):.4f}\n")
                    f.write(f"    BOM Sensitivity: {train_metrics.get('bom_sensitivity', 0):.4f}\n")
                    f.write(f"    BOM Specificity: {train_metrics.get('bom_specificity', 0):.4f}\n")

                    f.write("  éªŒè¯é›†æŒ‡æ ‡:\n")
                    f.write(f"    BOM AUC: {val_metrics.get('bom_auc', 0):.4f}\n")
                    f.write(f"    BOM Accuracy: {val_metrics.get('bom_accuracy', 0):.4f}\n")
                    f.write(f"    BOM Sensitivity: {val_metrics.get('bom_sensitivity', 0):.4f}\n")
                    f.write(f"    BOM Specificity: {val_metrics.get('bom_specificity', 0):.4f}\n")

                    # è¾…åŠ©ä»»åŠ¡å‡†ç¡®ç‡
                    f.write("  è¾…åŠ©ä»»åŠ¡å‡†ç¡®ç‡:\n")
                    aux_tasks = ['ti_rads', 'composition', 'echo', 'foci', 'margin', 'shape']
                    for task in aux_tasks:
                        train_acc = train_metrics.get(f'{task}_accuracy', 0)
                        val_acc = val_metrics.get(f'{task}_accuracy', 0)
                        f.write(f"    {task.capitalize():<12} - è®­ç»ƒ: {train_acc:.3f}, éªŒè¯: {val_acc:.3f}\n")
                    f.write("\n")

                # 6. ç‹¬ç«‹éªŒè¯é›†æœ€ç»ˆç»“æœ
                if self.final_verify_info:
                    f.write("ğŸ§ª ç‹¬ç«‹éªŒè¯é›†æœ€ç»ˆç»“æœ:\n")
                    f.write(f"  æ•°æ®é›†: {config['verify_data']}\n")
                    f.write(f"  BOM AUC: {self.final_verify_info.get('bom_auc', 0):.4f}\n")
                    f.write(f"  BOM Accuracy: {self.final_verify_info.get('bom_accuracy', 0):.4f}\n")
                    f.write(f"  BOM Sensitivity: {self.final_verify_info.get('bom_sensitivity', 0):.4f}\n")
                    f.write(f"  BOM Specificity: {self.final_verify_info.get('bom_specificity', 0):.4f}\n")

                    # è¾…åŠ©ä»»åŠ¡å‡†ç¡®ç‡
                    f.write("  è¾…åŠ©ä»»åŠ¡å‡†ç¡®ç‡:\n")
                    for task in aux_tasks:
                        acc = self.final_verify_info.get(f'{task}_accuracy', 0)
                        f.write(f"    {task.capitalize():<12}: {acc:.4f}\n")
                    f.write("\n")

                # 7. å®Œæ•´è®­ç»ƒæ—¥å¿—
                f.write("=" * 80 + "\n")
                f.write("ğŸ“ å®Œæ•´è®­ç»ƒæ—¥å¿—:\n")
                f.write("=" * 80 + "\n")
                for log_line in self.log_buffer:
                    f.write(log_line + "\n")

            print(f"ğŸ“„ è®­ç»ƒæŠ¥å‘Šå·²ä¿å­˜: {self.log_file_path}")

        except Exception as e:
            print(f"âŒ ä¿å­˜è®­ç»ƒæŠ¥å‘Šå¤±è´¥: {e}")

# =============================================================================
# æ ¸å¿ƒå‡½æ•°
# =============================================================================

def get_device():
    """è·å–æœ€ä½³å¯ç”¨è®¾å¤‡ - CUDAä¼˜å…ˆ"""
    if torch.cuda.is_available():
        # æ‰“å°å¯ç”¨GPUä¿¡æ¯
        num_gpus = torch.cuda.device_count()
        print(f"ğŸ® æ£€æµ‹åˆ° {num_gpus} ä¸ª CUDA GPU:")
        for i in range(num_gpus):
            gpu_name = torch.cuda.get_device_name(i)
            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
            print(f"    GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)")
        return torch.device("cuda")
    if torch.backends.mps.is_available():
        return torch.device("mps")
    return torch.device("cpu")


def get_num_gpus():
    """è·å–å¯ç”¨GPUæ•°é‡"""
    if torch.cuda.is_available():
        return torch.cuda.device_count()
    return 1

def load_config():
    """åŠ è½½é…ç½®"""
    return CONFIG

def extract_date_from_access_no(access_no):
    """ä»access_noä¸­æå–å¹´æœˆä¿¡æ¯ (YYYYMM)"""
    try:
        parts = access_no.split('.')
        if len(parts) >= 2:
            datetime_str = parts[1]
            if len(datetime_str) >= 6:
                year_month = datetime_str[:6]
                if len(year_month) == 6 and year_month.isdigit():
                    return year_month
    except Exception:
        pass
    return None

def extract_image_index_from_sop_uid(sop_uid):
    """ä»sop_uidä¸­æå–image_index (ä»¥'.'åˆ†éš”çš„å€’æ•°ç¬¬äºŒæ®µ)"""
    try:
        parts = str(sop_uid).split('.')
        if len(parts) >= 2:
            # å€’æ•°ç¬¬äºŒæ®µ
            image_index_str = parts[-2]
            # å°è¯•è½¬æ¢ä¸ºæ•´æ•°
            return int(image_index_str)
    except (ValueError, IndexError):
        pass
    return None

def add_image_index_column(df):
    """ä¸ºDataFrameæ·»åŠ image_indexåˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨çš„è¯ï¼‰"""
    if 'image_index' not in df.columns:
        print("    - Generating image_index column from sop_uid...")
        df['image_index'] = df['sop_uid'].apply(extract_image_index_from_sop_uid)
        # ç»Ÿè®¡ç”Ÿæˆç»“æœ
        valid_count = df['image_index'].notna().sum()
        total_count = len(df)
        print(f"    - Generated image_index for {valid_count}/{total_count} records ({valid_count/total_count:.1%})")
    else:
        print("    - image_index column already exists.")
    return df

def read_csv_with_encoding(file_path, logger=None):
    """
    å°è¯•ä½¿ç”¨ä¸åŒç¼–ç è¯»å–CSVæ–‡ä»¶
    """
    encodings = ['utf-8', 'gbk', 'gb2312', 'latin1', 'cp1252']

    for encoding in encodings:
        try:
            df = pd.read_csv(file_path, encoding=encoding)
            if logger:
                logger.log(f"    - Successfully loaded with {encoding} encoding.")
            return df
        except UnicodeDecodeError:
            continue

    raise ValueError(f"Failed to read {file_path} with any of the tried encodings: {encodings}")

def apply_all_filters(df, config, df_name="DataFrame", skip_time_filter=False):
    """
    å¯¹ç»™å®šçš„DataFrameåº”ç”¨æ‰€æœ‰ç­›é€‰è§„åˆ™.
    """
    print(f"\nApplying all filters to {df_name}...")
    original_count = len(df)

    # 0. æ·»åŠ image_indexåˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    df = add_image_index_column(df)

    # 1. image_indexç­›é€‰
    print("  - Rule 1: Filtering by image_index...")
    image_index_threshold = config.get('image_index_threshold', 16)
    print(f"skipping image_index filtering")
    # if 'image_index' in df.columns:
    #     # å…ˆç»Ÿè®¡æœ‰æ•ˆçš„image_index
    #     valid_image_index_mask = df['image_index'].notna()
    #     valid_count_before = valid_image_index_mask.sum()
    #
    #     # å¯¹æœ‰æ•ˆçš„image_indexè¿›è¡Œè¿‡æ»¤
    #     image_index_mask = (df['image_index'].notna()) & (df['image_index'] > image_index_threshold)
    #     removed_count = image_index_mask.sum()
    #     df = df[~image_index_mask]
    #
    #     print(f"    - Found {valid_count_before} records with valid image_index")
    #     print(f"    - Removed {removed_count} records with image_index > {image_index_threshold}")
    # else:
    #     print(f"    - No image_index column found, skipping image_index filtering")

    # 2. æ—¶é—´ç­›é€‰ (å¯é€‰æ‹©è·³è¿‡)
    if not skip_time_filter:
        print("  - Rule 2: Filtering by date...")
        df['year_month'] = df['access_no'].apply(extract_date_from_access_no)
        time_mask = df['year_month'].isin(config['exclude_months'])
        df = df[~time_mask].drop(columns=['year_month'])
        print(f"    - Removed {time_mask.sum()} records from excluded months.")
    else:
        print("  - Rule 2: Skipping date filtering for verification data.")

    # 3. TI-RADSç­›é€‰
    print("  - Rule 3: not Filter by TI-RADS level...")
    #ti_rads_mask = df['ti_rads'].isin(config['exclude_ti_rads'])
    #df = df[~ti_rads_mask]
    #print(f"    - Removed {ti_rads_mask.sum()} records with excluded TI-RADS.")
    
    # 4. ç–‘ä¼¼é”™æ ‡æ ·æœ¬ç­›é€‰ (ä»…å¯¹è®­ç»ƒé›†åº”ç”¨)
    threshold = config.get('OOF_p_true_threshold', 0.5)
    if threshold > 0 and 'p_true' in df.columns:
        print("  - Rule 4: Filtering suspicious OOF samples...")
        required_cols = ['p_true', 'predicted_class', 'bom']

        # ç¡®ä¿åˆ—å­˜åœ¨ä¸”ä¸ºæ•°å€¼ç±»å‹
        for col in required_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')

        # ä»…å¯¹å­˜åœ¨æ‰€éœ€åˆ—çš„è¡Œè¿›è¡Œæ“ä½œ
        valid_oof_rows = df.dropna(subset=required_cols)
        oof_mask = (valid_oof_rows['p_true'] < threshold) & (valid_oof_rows['predicted_class'] != valid_oof_rows['bom'])

        # è·å–è¦ç§»é™¤çš„è¡Œçš„ç´¢å¼•
        indices_to_remove = valid_oof_rows[oof_mask].index
        df = df.drop(indices_to_remove)
        print(f"    - Removed {len(indices_to_remove)} suspicious OOF samples (p_true < {threshold}).")
    elif threshold == 0:
        print("  - Rule 4: Skipping OOF filtering (OOF_p_true_threshold=0).")

    final_count = len(df)
    print(f"  - Filtering complete. Kept {final_count}/{original_count} records ({final_count/original_count:.2%})")
    
    return df.reset_index(drop=True)

def get_transforms_v60():
    """V60 æ•°æ®å¢å¼ºç­–ç•¥"""
    train_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),
        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1),
        transforms.RandomGrayscale(p=0.1),
        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        transforms.RandomErasing(p=0.25, scale=(0.02, 0.1))
    ])
    
    val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    return train_transform, val_transform

# --- æ•°æ®é›†ç±» (V60 å¤šä»»åŠ¡ç‰ˆ) ---
class NoduleFeatureDataset_V60(Dataset):
    """V60æ•°æ®é›†ç±» - æ”¯æŒBOM, TI-RADS, å’Œ5ä¸ªè¶…å£°å¾è±¡çš„å¤šä»»åŠ¡åˆ†ç±»"""
    def __init__(self, df, image_root, feature_mapping, transform=None):
        self.df = df.copy()
        self.image_root = image_root
        self.feature_mapping = feature_mapping
        self.transform = transform
        
        self.tasks = list(feature_mapping.keys())
        
        # ä¸ºæ¯ä¸ªå¾è±¡åˆ›å»ºåå‘æ˜ å°„ï¼Œç”¨äºå°†æ–‡æœ¬æ ‡ç­¾è½¬æ¢ä¸ºæ•´æ•°
        self.label_to_int_maps = self._create_label_maps()

    def _create_label_maps(self):
        label_maps = {}
        # 'bom' å’Œ 'ti_rads' å·²ç»åœ¨æ•°å€¼æ˜ å°„æ–‡ä»¶ä¸­å®šä¹‰å¥½äº†
        for task in self.tasks:
            label_maps[task] = self.feature_mapping[task]
        return label_maps

    def __len__(self): 
        return len(self.df)
        
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        image_path = os.path.join(self.image_root, row['access_no'], f"{row['sop_uid']}.jpg")

        try:
            image = Image.open(image_path).convert('RGB')
        except FileNotFoundError:
            image = Image.new('RGB', (224, 224), (0, 0, 0)) # Return a black image
            print(f"image not found:{image_path}")

        if self.transform:
            image = self.transform(image)

        item = {'image': image, 'access_no': row['access_no'], 'sop_uid': row['sop_uid']}

        # ä¸ºæ¯ä¸ªä»»åŠ¡è·å–æ ‡ç­¾å’Œæœ‰æ•ˆæ€§æ ‡å¿—
        for task in self.tasks:
            raw_val = row.get(task, np.nan)
            label_val = -1
            is_valid = 0.0

            if pd.notna(raw_val):
                # The keys in our mapping are strings. Convert raw_val to string for lookup.
                # e.g., for ti_rads, raw_val might be 1.0, we need '1'
                key = str(raw_val) if not isinstance(raw_val, str) else raw_val
                if isinstance(raw_val, float) and raw_val.is_integer():
                    key = str(int(raw_val))

                task_map = self.label_to_int_maps[task]

                if key in task_map:
                    label_val = task_map[key]
                    is_valid = 1.0

                    # Special handling for ti_rads (convert 1-5 to 0-4 for loss function)
                    if task == 'ti_rads':
                        label_val -= 1
            
            item[task] = torch.tensor(label_val, dtype=torch.long)
            item[f'{task}_valid'] = torch.tensor(is_valid, dtype=torch.float32)
            
        return item

# --- LMDBæ•°æ®é›†ç±» (é«˜é€ŸI/Oç‰ˆ) ---
class NoduleFeatureDataset_LMDB(Dataset):
    """LMDBæ•°æ®é›†ç±» - é«˜é€ŸI/Oï¼Œæ”¯æŒBOM, TI-RADS, å’Œ5ä¸ªè¶…å£°å¾è±¡çš„å¤šä»»åŠ¡åˆ†ç±»"""
    def __init__(self, lmdb_path, feature_mapping, transform=None, indices=None):
        import lmdb
        import pickle
        
        self.lmdb_path = lmdb_path
        self.feature_mapping = feature_mapping
        self.transform = transform
        self.tasks = list(feature_mapping.keys())
        self.label_to_int_maps = {task: feature_mapping[task] for task in self.tasks}
        
        # å»¶è¿Ÿæ‰“å¼€LMDBï¼ˆé¿å…pickleé—®é¢˜ï¼‰
        self.env = None
        
        # ä¸´æ—¶æ‰“å¼€è¯»å–å…ƒæ•°æ®
        temp_env = lmdb.open(lmdb_path, readonly=True, lock=False)
        with temp_env.begin(write=False) as txn:
            meta = pickle.loads(txn.get(b'__meta__'))
            total_samples = meta['num_samples']
        temp_env.close()
        
        # æ”¯æŒç´¢å¼•è¿‡æ»¤ï¼ˆç”¨äºè®­ç»ƒ/éªŒè¯åˆ’åˆ†ï¼‰
        if indices is not None:
            self.indices = list(indices)
            self.num_samples = len(self.indices)
        else:
            self.indices = list(range(total_samples))
            self.num_samples = total_samples
        
        print(f"    LMDBæ•°æ®é›†åŠ è½½å®Œæˆ: {self.num_samples} æ ·æœ¬ (æ€»å…±{total_samples})")
    
    def _init_db(self):
        """åœ¨æ¯ä¸ªworkerä¸­å»¶è¿Ÿåˆå§‹åŒ–LMDBè¿æ¥"""
        if self.env is None:
            import lmdb
            self.env = lmdb.open(self.lmdb_path, readonly=True, lock=False, readahead=True, meminit=False)

    def __len__(self): 
        return self.num_samples
        
    def __getitem__(self, idx):
        import pickle
        from io import BytesIO
        
        # å»¶è¿Ÿåˆå§‹åŒ–LMDBè¿æ¥
        self._init_db()
        
        # æ˜ å°„åˆ°å®é™…LMDBç´¢å¼•
        real_idx = self.indices[idx]
        
        # ä»LMDBè¯»å–æ•°æ®
        with self.env.begin(write=False) as txn:
            value = txn.get(f"{real_idx}".encode())
            if value is None:
                # fallback: è¿”å›ç©ºæ•°æ®
                return self._get_empty_item()
            data = pickle.loads(value)
        
        # è§£ç å›¾åƒ
        image_bytes = data['image']
        image = Image.open(BytesIO(image_bytes)).convert('RGB')
        
        if self.transform:
            image = self.transform(image)
        
        item = {'image': image, 'access_no': data['access_no'], 'sop_uid': data['sop_uid']}
        
        # ä¸ºæ¯ä¸ªä»»åŠ¡è·å–æ ‡ç­¾å’Œæœ‰æ•ˆæ€§æ ‡å¿—
        for task in self.tasks:
            raw_val = data.get(task)
            label_val = -1
            is_valid = 0.0
            
            if raw_val is not None and pd.notna(raw_val):
                key = str(raw_val) if not isinstance(raw_val, str) else raw_val
                if isinstance(raw_val, float) and raw_val == int(raw_val):
                    key = str(int(raw_val))
                
                task_map = self.label_to_int_maps[task]
                if key in task_map:
                    label_val = task_map[key]
                    is_valid = 1.0
                    if task == 'ti_rads':
                        label_val -= 1
            
            item[task] = torch.tensor(label_val, dtype=torch.long)
            item[f'{task}_valid'] = torch.tensor(is_valid, dtype=torch.float32)
        
        return item
    
    def _get_empty_item(self):
        """è¿”å›ç©ºæ•°æ®é¡¹"""
        item = {
            'image': torch.zeros(3, 224, 224),
            'access_no': '',
            'sop_uid': ''
        }
        for task in self.tasks:
            item[task] = torch.tensor(-1, dtype=torch.long)
            item[f'{task}_valid'] = torch.tensor(0.0, dtype=torch.float32)
        return item

# --- V60 EfficientNet-B0 å¤šä»»åŠ¡æ¨¡å‹ ---
class MultiTaskNoduleCNN_V60(nn.Module):
    """V60 EfficientNet-B0æ¨¡å‹ - æ”¯æŒ7ä¸ªåˆ†ç±»ä»»åŠ¡"""
    def __init__(self, feature_mappings, dropout_rate=0.4):
        super().__init__()
        self.mappings = feature_mappings

        from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights
        self.backbone = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)
        backbone_features = 1280
        self.backbone.classifier = nn.Identity()

        self.shared_features = nn.Sequential(
            nn.Linear(backbone_features, 512),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(dropout_rate * 0.75)
        )

        # åŠ¨æ€åˆ›å»ºåˆ†ç±»å¤´
        self.heads = nn.ModuleDict()
        for task, mapping in self.mappings.items():
            num_classes = len(mapping)
            self.heads[task] = nn.Sequential(
                nn.Linear(256, 128),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(128, num_classes)
            )

    def forward(self, x):
        features = self.backbone(x)
        shared = self.shared_features(features)

        outputs = {}
        for task, head in self.heads.items():
            outputs[task] = head(shared)

        return outputs

# --- V60æŸå¤±ç®¡ç†å™¨ ---
class FocusedLossManager_V60:
    """V60 æŸå¤±ç®¡ç†å™¨ - ä¸º7ä¸ªä»»åŠ¡è®¡ç®—å¸¦æƒé‡çš„æŸå¤±"""
    def __init__(self, loss_weights, device):
        self.loss_weights = loss_weights
        self.device = device
        self.tasks = list(loss_weights.keys())
        self.loss_fn = nn.CrossEntropyLoss(reduction='none')

    def __call__(self, outputs, batch):
        losses = {}
        total_loss = 0

        for task in self.tasks:
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæ ‡ç­¾
            if f'{task}_valid' in batch and batch[f'{task}_valid'].sum() > 0:
                # è·å–logitså’Œlabels
                logits = outputs[task]
                labels = batch[task]
                valid_mask = batch[f'{task}_valid'] > 0

                # åªå¯¹æœ‰æ•ˆæ ·æœ¬è®¡ç®—æŸå¤±
                valid_logits = logits[valid_mask]
                valid_labels = labels[valid_mask]
                loss = self.loss_fn(valid_logits, valid_labels).mean()
                losses[task] = loss
                total_loss += self.loss_weights[task] * loss

        losses['total'] = total_loss
        return losses

# --- è®­ç»ƒå’ŒéªŒè¯å‡½æ•° ---
def train_epoch(model, loader, loss_fn, optimizer, device, config=None):
    model.train()
    total_loss = 0
    # å¤„ç†DataParallelåŒ…è£…
    model_mappings = model.module.mappings if isinstance(model, nn.DataParallel) else model.mappings
    metrics_calc = DetailedMetricsCalculator_V60(model_mappings)
    metrics_calc.reset()  # ç¡®ä¿é‡ç½®

    for batch in tqdm(loader, desc="Training", leave=False):
        for k, v in batch.items():
            if isinstance(v, torch.Tensor):
                batch[k] = v.to(device)

        optimizer.zero_grad()
        outputs = model(batch['image'])
        losses = loss_fn(outputs, batch)
        losses['total'].backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=config['max_grad_norm'] if config else 1.0)
        optimizer.step()

        total_loss += losses['total'].item()
        metrics_calc.update(outputs, batch)

    return total_loss / len(loader), metrics_calc.compute_metrics()

def validate_epoch(model, loader, loss_fn, device):
    model.eval()
    total_loss = 0
    # å¤„ç†DataParallelåŒ…è£…
    model_mappings = model.module.mappings if isinstance(model, nn.DataParallel) else model.mappings
    metrics_calc = DetailedMetricsCalculator_V60(model_mappings)
    metrics_calc.reset()  # ç¡®ä¿é‡ç½®

    with torch.no_grad():
        for batch in tqdm(loader, desc="Validating", leave=False):
            for k, v in batch.items():
                if isinstance(v, torch.Tensor):
                    batch[k] = v.to(device)

            outputs = model(batch['image'])
            losses = loss_fn(outputs, batch)
            total_loss += losses['total'].item()
            metrics_calc.update(outputs, batch)

    return total_loss / len(loader), metrics_calc.compute_metrics()

# --- V60æŒ‡æ ‡è®¡ç®—å™¨ ---
class DetailedMetricsCalculator_V60:
    def __init__(self, mappings):
        self.mappings = mappings
        self.tasks = list(self.mappings.keys())
        self.reset()

    def reset(self):
        self.targets = {task: [] for task in self.tasks}
        self.preds = {task: [] for task in self.tasks}
        # boméœ€è¦æ¦‚ç‡ç”¨äºAUCè®¡ç®—
        self.bom_probs = []

    def update(self, outputs, batch):
        for task in self.tasks:
            if batch[f'{task}_valid'].sum() > 0:
                valid_indices = batch[f'{task}_valid'] > 0

                self.targets[task].append(batch[task][valid_indices])
                self.preds[task].append(torch.argmax(outputs[task], dim=1)[valid_indices])

                if task == 'bom':
                    # å…ˆåº”ç”¨valid_indicesï¼Œå†è®¡ç®—softmaxå’Œå–ç¬¬1ç±»æ¦‚ç‡
                    bom_logits_valid = outputs['bom'][valid_indices]
                    bom_probs_valid = torch.softmax(bom_logits_valid, dim=1)[:, 1]
                    self.bom_probs.append(bom_probs_valid)


    def compute_metrics(self):
        metrics = {}
        for task in self.tasks:
            # æ›´ä¸¥æ ¼çš„æ£€æŸ¥ï¼šç¡®ä¿æœ‰æœ‰æ•ˆæ•°æ®
            if not self.targets[task] or len(self.targets[task]) == 0:
                continue

            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å¼ é‡éƒ½éç©º
            valid_targets = [t for t in self.targets[task] if t.numel() > 0]
            valid_preds = [p for p in self.preds[task] if p.numel() > 0]

            if len(valid_targets) == 0 or len(valid_preds) == 0:
                continue

            targets = torch.cat(valid_targets).cpu().numpy()
            preds = torch.cat(valid_preds).cpu().numpy()

            if task == 'bom':
                valid_probs = [p for p in self.bom_probs if p.numel() > 0]
                if len(valid_probs) == 0:
                    continue

                probs = torch.cat(valid_probs).detach().cpu().numpy()

                if len(np.unique(targets)) < 2:
                    # å½“åªæœ‰ä¸€ä¸ªç±»åˆ«æ—¶ï¼Œæ— æ³•è®¡ç®—AUCï¼Œè®¾ä¸ºNaN
                    metrics['bom_auc'] = float('nan')
                else:
                    metrics['bom_auc'] = roc_auc_score(targets, probs)

                tn, fp, fn, tp = confusion_matrix(targets, preds, labels=[0, 1]).ravel()
                metrics['bom_sensitivity'] = tp / (tp + fn) if (tp + fn) > 0 else 0
                metrics['bom_specificity'] = tn / (tn + fp) if (tn + fp) > 0 else 0
                metrics['bom_accuracy'] = (tp + tn) / (tp + tn + fp + fn)
            else:
                # å…¶ä»–ä»»åŠ¡è®¡ç®—å‡†ç¡®ç‡
                accuracy = (preds == targets).mean()
                metrics[f'{task}_accuracy'] = accuracy
        return metrics

def print_results(epoch, train_metrics, val_metrics):
    print(f"\nğŸ“Š Epoch {epoch+1} Results (V64):")
    # BOM æŒ‡æ ‡ - å¤„ç†NaNå€¼
    def format_metric(value, default=0):
        if value is None or (isinstance(value, float) and np.isnan(value)):
            return "N/A"
        return f"{value:.4f}"

    train_auc = format_metric(train_metrics.get('bom_auc'))
    train_acc = format_metric(train_metrics.get('bom_accuracy'))
    train_sens = format_metric(train_metrics.get('bom_sensitivity'))
    train_spec = format_metric(train_metrics.get('bom_specificity'))

    val_auc = format_metric(val_metrics.get('bom_auc'))
    val_acc = format_metric(val_metrics.get('bom_accuracy'))
    val_sens = format_metric(val_metrics.get('bom_sensitivity'))
    val_spec = format_metric(val_metrics.get('bom_specificity'))

    print(f"  ğŸ¯ Training:   AUC={train_auc}, Acc={train_acc}, Sens={train_sens}, Spec={train_spec}")
    print(f"  ğŸ” Validation: AUC={val_auc}, Acc={val_acc}, Sens={val_sens}, Spec={val_spec}")

    # è¾…åŠ©ä»»åŠ¡æŒ‡æ ‡
    aux_tasks = [k.replace('_accuracy', '') for k in val_metrics.keys() if '_accuracy' in k and 'bom' not in k]
    for task in sorted(aux_tasks):
        train_acc = train_metrics.get(f'{task}_accuracy', 0)
        val_acc = val_metrics.get(f'{task}_accuracy', 0)
        print(f"    - {task.capitalize():<12} Train Acc: {train_acc:.3f}, Val Acc: {val_acc:.3f}")

# --- å¯è§†åŒ–å‡½æ•° (å‚è€ƒV37) ---
def create_image_grid(images, labels, predictions, access_nos, sop_uids, title, save_path):
    plt.rcParams['font.family'] = 'DejaVu Sans'
    fig, axes = plt.subplots(6, 6, figsize=(20, 24))  # å¢åŠ é«˜åº¦ä»¥å®¹çº³æ›´å¤šæ–‡æœ¬
    fig.suptitle(title, fontsize=16, fontweight='bold')

    def split_text_to_lines(text, max_chars_per_line=20):
        """å°†é•¿æ–‡æœ¬åˆ†å‰²æˆå¤šè¡Œ"""
        if len(text) <= max_chars_per_line:
            return [text]

        lines = []
        for i in range(0, len(text), max_chars_per_line):
            lines.append(text[i:i + max_chars_per_line])
        return lines

    for i in range(6):
        for j in range(6):
            ax = axes[i, j]
            idx = i * 6 + j
            if idx >= len(images):
                ax.axis('off')
                continue

            img = np.clip(images[idx].permute(1, 2, 0).cpu().numpy(), 0, 1)
            ax.imshow(img)

            bom_label = labels[idx]
            pred_val = predictions[idx]
            pred_class = 1 if pred_val > 0.5 else 0
            color = 'green' if bom_label == pred_class else 'red'

            # å·¦ä¸Šè§’æ˜¾ç¤ºBOMæ ‡ç­¾
            ax.text(0.05, 0.95, f"BOM: {bom_label}", transform=ax.transAxes,
                   color='white', fontsize=10, fontweight='bold',
                   bbox=dict(boxstyle="round,pad=0.3", fc='black', alpha=0.7),
                   va='top')

            # å³ä¸Šè§’æ˜¾ç¤ºé¢„æµ‹æ¦‚ç‡
            ax.text(0.95, 0.95, f"{pred_val:.3f}", transform=ax.transAxes,
                   color=color, fontsize=10, fontweight='bold',
                   bbox=dict(boxstyle="round,pad=0.3", fc='white', alpha=0.8),
                   ha='right', va='top')

            # å›¾åƒä¸‹æ–¹æ˜¾ç¤ºå®Œæ•´çš„æ ‡è¯†ä¿¡æ¯
            access_no = access_nos[idx]
            sop_uid = sop_uids[idx]

            # æ˜¾ç¤ºaccess_no (ç¼©å†™)
            ax.text(0.5, -0.02, f"Access: {access_no[:12]}{'...' if len(access_no) > 12 else ''}",
                   transform=ax.transAxes, color='blue', fontsize=7,
                   ha='center', va='top', fontweight='bold')

            # åˆ†è¡Œæ˜¾ç¤ºå®Œæ•´çš„sop_uid
            sop_lines = split_text_to_lines(sop_uid, max_chars_per_line=25)
            for line_idx, line in enumerate(sop_lines):
                y_pos = -0.06 - (line_idx * 0.04)  # æ¯è¡Œé—´éš”0.04
                ax.text(0.5, y_pos, line,
                       transform=ax.transAxes, color='darkgreen', fontsize=6,
                       ha='center', va='top', fontfamily='monospace')

            # åœ¨å³ä¸‹è§’æ˜¾ç¤ºå›¾åƒåºå·ï¼Œä¾¿äºå¿«é€Ÿå®šä½
            ax.text(0.95, 0.05, f"#{idx+1}", transform=ax.transAxes,
                   color='orange', fontsize=8, fontweight='bold',
                   bbox=dict(boxstyle="round,pad=0.2", fc='yellow', alpha=0.6),
                   ha='right', va='bottom')

            ax.axis('off')

    # è°ƒæ•´å¸ƒå±€ï¼Œä¸ºåº•éƒ¨æ–‡æœ¬ç•™å‡ºæ›´å¤šç©ºé—´
    plt.tight_layout(rect=[0, 0.02, 1, 0.96])
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"    ğŸ“¸ Image grid saved: {save_path}")
    plt.close()

def visualize_epoch_samples(model, loader, device, epoch, output_dir, set_name="val"):
    model.eval()

    # è®¾ç½®éšæœºç§å­ï¼Œæ¯ä¸ªepochéƒ½ä¸åŒ
    random.seed(epoch * 1000 + 42)
    torch.manual_seed(epoch * 1000 + 42)

    total_batches = len(loader)
    if total_batches == 0:
        print(f"    âš ï¸ {set_name} loader is empty, skipping visualization.")
        return

    # è·¨batché‡‡æ ·ï¼Œé¿å…é‡å¤å›¾åƒ
    num_samples = 36
    samples_per_batch = max(1, num_samples // min(total_batches, num_samples))

    # éšæœºé€‰æ‹©å¤šä¸ªbatch
    selected_batches = random.sample(range(total_batches), min(total_batches, (num_samples + samples_per_batch - 1) // samples_per_batch))

    images, labels, predictions, access_nos, sop_uids = [], [], [], [], []
    collected_samples = 0

    for batch_idx, batch in enumerate(loader):
        if batch_idx not in selected_batches or collected_samples >= num_samples:
            continue

        # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
        for k, v in batch.items():
            if isinstance(v, torch.Tensor):
                batch[k] = v.to(device)

        with torch.no_grad():
            outputs = model(batch['image'])
            probs = torch.softmax(outputs['bom'], dim=1)[:, 1]

        # ä»å½“å‰batchä¸­é‡‡æ ·ï¼Œç¡®ä¿ä¸é‡å¤access_no
        batch_size = len(batch['image'])
        remaining_samples = min(samples_per_batch, num_samples - collected_samples, batch_size)

        # æŒ‰access_noå»é‡é‡‡æ ·
        unique_access_indices = []
        seen_access_nos = set()

        for i in range(batch_size):
            access_no = batch['access_no'][i]
            if access_no not in seen_access_nos:
                unique_access_indices.append(i)
                seen_access_nos.add(access_no)

        # ä»å»é‡åçš„ç´¢å¼•ä¸­éšæœºé€‰æ‹©
        if len(unique_access_indices) > 0:
            selected_indices = random.sample(unique_access_indices, min(remaining_samples, len(unique_access_indices)))

            for idx in selected_indices:
                if collected_samples >= num_samples:
                    break

                img = batch['image'][idx].cpu()
                # åæ ‡å‡†åŒ–
                img = img * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1) + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
                images.append(img)
                labels.append(batch['bom'][idx].cpu().item())
                predictions.append(probs[idx].cpu().item())
                access_nos.append(batch['access_no'][idx])
                sop_uids.append(batch['sop_uid'][idx])
                collected_samples += 1

    # å¦‚æœæ ·æœ¬ä¸è¶³36å¼ ï¼Œç”¨å®é™…æ”¶é›†åˆ°çš„æ•°é‡
    actual_samples = len(images)

    save_path = os.path.join(output_dir, f'{set_name}_samples_epoch_{epoch + 1}.png')
    create_image_grid(images, labels, predictions, access_nos, sop_uids,
                     title=f"{set_name.capitalize()} Samples - Epoch {epoch + 1} ({actual_samples} unique patients)",
                     save_path=save_path)

    print(f"    ğŸ“¸ å¯è§†åŒ–å®Œæˆ: ä»{len(selected_batches)}ä¸ªbatchä¸­é‡‡é›†{actual_samples}å¼ å›¾åƒ (å»é‡å)")

def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    # è®¾ç½®multiprocessingå¯åŠ¨æ–¹æ³•ä¸ºspawnï¼Œè§£å†³Python 3.14å…¼å®¹æ€§é—®é¢˜
    import multiprocessing
    try:
        multiprocessing.set_start_method('spawn', force=True)
    except RuntimeError:
        pass  # å·²ç»è®¾ç½®è¿‡äº†
    
    # CUDAç¯å¢ƒä¼˜åŒ–è®¾ç½®
    if torch.cuda.is_available():
        # å¯ç”¨cuDNNè‡ªåŠ¨è°ƒä¼˜ï¼Œé’ˆå¯¹å›ºå®šè¾“å…¥å°ºå¯¸åŠ é€Ÿå·ç§¯æ“ä½œ
        torch.backends.cudnn.benchmark = True
        # å¯ç”¨TF32ä»¥åœ¨AmpereåŠæ›´æ–°æ¶æ„ä¸ŠåŠ é€Ÿè®¡ç®—ï¼ˆå¦‚5090ï¼‰
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True
        # è®¾ç½®é»˜è®¤CUDAè®¾å¤‡
        torch.cuda.set_device(0)
    
    device = get_device()
    config = load_config()
    output_dir = config['output_dir']
    os.makedirs(output_dir, exist_ok=True)
    writer = SummaryWriter(config['tensorboard_dir'])

    # åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
    log_file_path = os.path.join(output_dir, f'training_report_{config["model_name"]}.txt')
    logger = TrainingLogger(log_file_path)

    logger.log("ğŸš€ V64 æ¨¡å‹è®­ç»ƒå¯åŠ¨ (EfficientNet-B0 å¤šä»»åŠ¡ç‰ˆ)")
    oof_status = "è·³è¿‡OOFç­›é€‰" if config['OOF_p_true_threshold'] == 0 else f"OOF_p_true_threshold={config['OOF_p_true_threshold']}"
    logger.log(f"ğŸ¯ æ ¸å¿ƒç›®æ ‡: {oof_status}, image_index_threshold={config['image_index_threshold']}")
    logger.log(f"ğŸ”¬ è®¾å¤‡: {device}")
    logger.log(f"ğŸ“ æ¨¡å‹ä¿å­˜ç›®å½•: {output_dir}")
    logger.log(f"ğŸ–¼ï¸ è®­ç»ƒå›¾åƒæ ¹ç›®å½•: {config['image_root']}")
    if 'verify_root' in config:
        logger.log(f"ğŸ§ª éªŒè¯å›¾åƒæ ¹ç›®å½•: {config['verify_root']}")
    else:
        logger.log(f"ğŸ§ª éªŒè¯å›¾åƒæ ¹ç›®å½•: {config['image_root']} (ä¸è®­ç»ƒç›¸åŒ)")

    # --- æ•°æ®åŠ è½½ ---
    logger.log(f"\nğŸ“Š Loading datasets:")

    # åŠ è½½è®­ç»ƒæ•°æ®é›†
    sop4_data_path = config['sop4_data']
    logger.log(f"  - Loading training data from: {sop4_data_path}")
    df_train_raw = read_csv_with_encoding(sop4_data_path, logger)
    logger.log(f"    - Found {len(df_train_raw)} raw training records.")

    # åº”ç”¨æ‰€æœ‰ç­›é€‰è§„åˆ™
    df_train_filtered = apply_all_filters(df_train_raw, config, df_name="Training Data")

    # åŠ è½½éªŒè¯æ•°æ®é›†
    verify_data_path = config['verify_data']
    logger.log(f"  - Loading verification data from: {verify_data_path}")
    df_verify_raw = read_csv_with_encoding(verify_data_path, logger)
    logger.log(f"    - Found {len(df_verify_raw)} raw verification records.")

    # åº”ç”¨æ‰€æœ‰ç­›é€‰è§„åˆ™ (è·³è¿‡æ—¶é—´è¿‡æ»¤)
    df_verify_filtered = apply_all_filters(df_verify_raw, config, df_name="Verification Data", skip_time_filter=True)

    # æ•°æ®ç»Ÿè®¡
    logger.log(f"\nğŸ“ˆ æœ€çµ‚è¨“ç·´æ•°æ®ç»Ÿè®¡:")
    logger.log(f"  æ€»æ ·æœ¬æ•°: {len(df_train_filtered)}")

    # æ•°æ®æºç»Ÿè®¡ (å¦‚æœå­˜åœ¨)
    if 'dataset_source' in df_train_filtered.columns:
        source_counts = df_train_filtered['dataset_source'].value_counts()
        logger.log(f"  æ•°æ®æºåˆ†å¸ƒ:")
        for source, count in source_counts.items():
            logger.log(f"    {source}: {count} ({count/len(df_train_filtered)*100:.1f}%)")

    # BOMç»Ÿè®¡
    if 'bom' in df_train_filtered.columns:
        bom_counts = df_train_filtered['bom'].value_counts().sort_index()
        bom_valid = df_train_filtered['bom'].notna().sum()
        logger.log(f"  BOMæœ‰æ•ˆæ ·æœ¬: {bom_valid} ({bom_valid/len(df_train_filtered)*100:.1f}%)")
        for bom_val, count in bom_counts.items():
            bom_name = "è‰¯æ€§" if bom_val == 0 else "æ¶æ€§"
            logger.log(f"    {bom_name}(BOM={bom_val}): {count} ({count/bom_valid*100:.1f}%)")

    # ç»Ÿè®¡å…¶ä»–ç‰¹å¾
    feature_mapping = json.load(open(config['feature_mapping_file'], 'r', encoding='utf-8'))
    for task in ['ti_rads', 'composition', 'echo', 'foci', 'margin', 'shape']:
        if task in df_train_filtered.columns:
            valid_count = df_train_filtered[task].notna().sum()
            logger.log(f"  {task.capitalize()}æœ‰æ•ˆæ ·æœ¬: {valid_count} ({valid_count/len(df_train_filtered)*100:.1f}%)")

    # æ•°æ®åˆ’åˆ† - æŒ‰access_noåˆ†ç»„ï¼Œé¿å…æ•°æ®æ³„éœ²
    logger.log(f"\nğŸ›¡ï¸ æŒ‰access_noåˆ†ç»„åˆ’åˆ†ï¼Œé¿å…æ•°æ®æ³„éœ²...")

    # ç»Ÿè®¡access_noåˆ†å¸ƒ
    access_groups = df_train_filtered['access_no'].nunique()
    logger.log(f"  æ•°æ®é›†åŒ…å« {access_groups} ä¸ªä¸åŒçš„access_no")

    # ä½¿ç”¨GroupShuffleSplitæŒ‰access_noåˆ†ç»„
    gss = GroupShuffleSplit(n_splits=1, test_size=config['test_size'], random_state=config['random_state'])
    train_idx, val_idx = next(gss.split(df_train_filtered, groups=df_train_filtered['access_no']))

    train_df = df_train_filtered.iloc[train_idx].reset_index(drop=True)
    val_df = df_train_filtered.iloc[val_idx].reset_index(drop=True)

    # éªŒè¯åˆ†ç»„æ•ˆæœ
    train_groups = train_df['access_no'].nunique()
    val_groups = val_df['access_no'].nunique()
    logger.log(f"  è®­ç»ƒé›†access_no: {train_groups} ä¸ª")
    logger.log(f"  éªŒè¯é›†access_no: {val_groups} ä¸ª")

    # æ£€æŸ¥æ˜¯å¦æœ‰é‡å 
    overlap = set(train_df['access_no'].unique()) & set(val_df['access_no'].unique())
    if len(overlap) == 0:
        logger.log(f"  âœ… æ•°æ®åˆ’åˆ†æˆåŠŸï¼Œæ— access_noé‡å ")
    else:
        logger.log(f"  âš ï¸ è­¦å‘Šï¼šå‘ç° {len(overlap)} ä¸ªé‡å çš„access_no")

    # åˆ›å»ºæ•°æ®é›†
    train_transform, val_transform = get_transforms_v60()
    
    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨LMDBåŠ é€Ÿ
    use_lmdb = config.get('use_lmdb', False)
    train_lmdb_exists = os.path.exists(config.get('train_lmdb_path', ''))
    
    if use_lmdb and train_lmdb_exists:
        logger.log(f"\nâš¡ ä½¿ç”¨LMDBé«˜é€Ÿæ•°æ®åŠ è½½æ¨¡å¼")
        logger.log(f"   LMDBè·¯å¾„: {config['train_lmdb_path']}")
        # LMDBå·²åŒ…å«è¿‡æ»¤åçš„æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨åˆ’åˆ†ç´¢å¼•
        train_set = NoduleFeatureDataset_LMDB(config['train_lmdb_path'], feature_mapping, train_transform, indices=train_idx)
        val_set = NoduleFeatureDataset_LMDB(config['train_lmdb_path'], feature_mapping, val_transform, indices=val_idx)
    else:
        if use_lmdb:
            logger.log(f"\nâš ï¸ LMDBæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–‡ä»¶åŠ è½½æ¨¡å¼")
            logger.log(f"   è¯·è¿è¡Œ: python create_lmdb_dataset.py --filter åˆ›å»ºLMDBæ•°æ®é›†")
        else:
            logger.log(f"\nğŸ“ ä½¿ç”¨ä¼ ç»Ÿæ–‡ä»¶åŠ è½½æ¨¡å¼")
        train_set = NoduleFeatureDataset_V60(train_df, config['image_root'], feature_mapping, train_transform)
        val_set = NoduleFeatureDataset_V60(val_df, config['image_root'], feature_mapping, val_transform)

    # DataLoaderé…ç½® - é’ˆå¯¹CUDAå¤šGPUç¯å¢ƒä¼˜åŒ–
    # LMDBæ¨¡å¼ä¸‹å¯ä»¥ä½¿ç”¨æ›´å¤šworkerï¼Œå› ä¸ºI/Oä¸å†æ˜¯ç“¶é¢ˆ
    num_workers = config['num_workers'] if not (use_lmdb and train_lmdb_exists) else min(config['num_workers'] * 2, 16)
    loader_kwargs = {
        'batch_size': config['batch_size'],
        'num_workers': num_workers,
        'pin_memory': True if torch.cuda.is_available() else False,
        'persistent_workers': True if num_workers > 0 else False,
        'prefetch_factor': 4 if num_workers > 0 else None,
    }
    train_loader = DataLoader(train_set, shuffle=True, **loader_kwargs)
    val_loader = DataLoader(val_set, shuffle=False, **loader_kwargs)

    logger.log(f"\nğŸ”„ æœ€ç»ˆæ•°æ®åˆ’åˆ†:")
    logger.log(f"  è®­ç»ƒé›†: {len(train_set)} æ ·æœ¬ ({train_groups} ä¸ªaccess_no)")
    logger.log(f"  éªŒè¯é›†: {len(val_set)} æ ·æœ¬ ({val_groups} ä¸ªaccess_no)")

    # ç»Ÿè®¡åˆ†ç»„åçš„BOMåˆ†å¸ƒ
    train_bom_dist = train_df['bom'].value_counts().sort_index()
    val_bom_dist = val_df['bom'].value_counts().sort_index()
    logger.log(f"  è®­ç»ƒé›†BOMåˆ†å¸ƒ: è‰¯æ€§{train_bom_dist.get(0, 0)}, æ¶æ€§{train_bom_dist.get(1, 0)}")
    logger.log(f"  éªŒè¯é›†BOMåˆ†å¸ƒ: è‰¯æ€§{val_bom_dist.get(0, 0)}, æ¶æ€§{val_bom_dist.get(1, 0)}")

    # å‡†å¤‡å®šæœŸéªŒè¯
    logger.log(f"\nğŸ§ª Setting up periodic verification on independent test set...")
    _, verify_transform = get_transforms_v60()

    # ç¡®å®šéªŒè¯å›¾åƒæ ¹ç›®å½•
    verify_image_root = config.get('verify_root', config['image_root'])
    verify_lmdb_exists = os.path.exists(config.get('verify_lmdb_path', ''))
    
    if use_lmdb and verify_lmdb_exists:
        logger.log(f"  - Using LMDB for verification: {config['verify_lmdb_path']}")
        verify_dataset = NoduleFeatureDataset_LMDB(config['verify_lmdb_path'], feature_mapping, verify_transform)
    else:
        logger.log(f"  - Using file-based verification: {verify_image_root}")
        verify_dataset = NoduleFeatureDataset_V60(df_verify_filtered, verify_image_root, feature_mapping, verify_transform)
    
    verify_loader = DataLoader(verify_dataset, shuffle=False, **loader_kwargs)
    logger.log(f"  - Verification will run every {config['verify_epoch_interval']} epochs on {len(verify_dataset)} samples.")

    # æ¨¡å‹åˆå§‹åŒ–
    model = MultiTaskNoduleCNN_V60(feature_mapping, dropout_rate=config['dropout_rate']).to(device)
    
    # å¤šGPUå¹¶è¡Œè®­ç»ƒæ”¯æŒ
    num_gpus = get_num_gpus()
    if config['use_multi_gpu'] and num_gpus > 1 and torch.cuda.is_available():
        gpu_ids = config['gpu_ids'] if config['gpu_ids'] else list(range(num_gpus))
        logger.log(f"\nğŸš€ å¯ç”¨å¤šGPUå¹¶è¡Œè®­ç»ƒ: ä½¿ç”¨ {len(gpu_ids)} ä¸ªGPU")
        logger.log(f"    GPU IDs: {gpu_ids}")
        model = nn.DataParallel(model, device_ids=gpu_ids)
        # è°ƒæ•´æœ‰æ•ˆbatch_size
        effective_batch_size = config['batch_size'] * len(gpu_ids)
        logger.log(f"    æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: {config['batch_size']} x {len(gpu_ids)} = {effective_batch_size}")
    else:
        logger.log(f"\nğŸ”§ å•GPU/CPUè®­ç»ƒæ¨¡å¼")
    
    loss_fn = FocusedLossManager_V60(config['loss_weights'], device)
    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', factor=0.5, patience=7, min_lr=1e-6)

    # æ¨¡å‹å‚æ•°ç»Ÿè®¡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    logger.log(f"\nğŸ—ï¸ æ¨¡å‹æ¶æ„ (EfficientNet-B0 å¤šä»»åŠ¡ç‰ˆ):")
    logger.log(f"  æ€»å‚æ•°: {total_params/1e6:.2f}M")
    logger.log(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params/1e6:.2f}M")
    logger.log(f"  å‚æ•°/æ ·æœ¬æ¯”: {total_params/len(train_set):.0f}:1")

    logger.log(f"\nâš–ï¸ æŸå¤±æƒé‡é…ç½®:")
    for task, weight in config['loss_weights'].items():
        logger.log(f"  - {task.capitalize():<12}: {weight}")

    # --- è®­ç»ƒå¾ªç¯ ---
    logger.log(f"\nğŸ¯ å¼€å§‹è®­ç»ƒ (æ—©åœè½®æ•°: {config['early_stop_patience']}):")
    num_epochs = config['num_epochs']
    best_auc = 0.0
    best_epoch = 0
    patience_counter = 0
    early_stop_patience = config['early_stop_patience']

    for epoch in range(num_epochs):
        # è®­ç»ƒå’ŒéªŒè¯
        train_loss, train_metrics = train_epoch(model, train_loader, loss_fn, optimizer, device, config)
        val_loss, val_metrics = validate_epoch(model, val_loader, loss_fn, device)

        current_auc = val_metrics.get('bom_auc', 0)
        scheduler.step(current_auc)

        # æ‰“å°ç»“æœ
        print_results(epoch, train_metrics, val_metrics)

        # å¯è§†åŒ–æ ·æœ¬
        visualize_epoch_samples(model, val_loader, device, epoch, output_dir, set_name="val")

        # TensorBoardè®°å½•
        writer.add_scalar('Train/Loss', train_loss, epoch)
        writer.add_scalar('Val/Loss', val_loss, epoch)
        writer.add_scalar('Train/BOM_AUC', train_metrics.get('bom_auc', 0), epoch)
        writer.add_scalar('Val/BOM_AUC', val_metrics.get('bom_auc', 0), epoch)
        writer.add_scalar('Train/BOM_Accuracy', train_metrics.get('bom_accuracy', 0), epoch)
        writer.add_scalar('Val/BOM_Accuracy', val_metrics.get('bom_accuracy', 0), epoch)
        writer.add_scalar('Train/BOM_Sensitivity', train_metrics.get('bom_sensitivity', 0), epoch)
        writer.add_scalar('Val/BOM_Sensitivity', val_metrics.get('bom_sensitivity', 0), epoch)
        writer.add_scalar('Train/BOM_Specificity', train_metrics.get('bom_specificity', 0), epoch)
        writer.add_scalar('Val/BOM_Specificity', val_metrics.get('bom_specificity', 0), epoch)

        # è®°å½•è¾…åŠ©ä»»åŠ¡æŒ‡æ ‡ (å¤„ç†DataParallelåŒ…è£…)
        model_mappings = model.module.mappings if isinstance(model, nn.DataParallel) else model.mappings
        for task in model_mappings.keys():
            if task == 'bom': continue
            train_acc = train_metrics.get(f'{task}_accuracy', 0)
            val_acc = val_metrics.get(f'{task}_accuracy', 0)
            writer.add_scalar(f'Train/{task.capitalize()}_Accuracy', train_acc, epoch)
            writer.add_scalar(f'Val/{task.capitalize()}_Accuracy', val_acc, epoch)

        # å®šæœŸåœ¨ç‹¬ç«‹éªŒè¯é›†ä¸Šè¿›è¡ŒéªŒè¯
        if (epoch + 1) % config['verify_epoch_interval'] == 0:
            logger.log(f"\n--- ğŸ§ª Periodic Verification on Independent Test Set (Epoch {epoch + 1}) ---")
            _, periodic_verify_metrics = validate_epoch(model, verify_loader, loss_fn, device)

            logger.log(f"  - AUC: {periodic_verify_metrics.get('bom_auc', 0):.4f}, "
                  f"Acc: {periodic_verify_metrics.get('bom_accuracy', 0):.4f}, "
                  f"Sens: {periodic_verify_metrics.get('bom_sensitivity', 0):.4f}, "
                  f"Spec: {periodic_verify_metrics.get('bom_specificity', 0):.4f}")

            # è®°å½•åˆ°TensorBoard
            writer.add_scalar('Verify/BOM_AUC', periodic_verify_metrics.get('bom_auc', 0), epoch)
            writer.add_scalar('Verify/BOM_Accuracy', periodic_verify_metrics.get('bom_accuracy', 0), epoch)
            writer.add_scalar('Verify/BOM_Sensitivity', periodic_verify_metrics.get('bom_sensitivity', 0), epoch)
            writer.add_scalar('Verify/BOM_Specificity', periodic_verify_metrics.get('bom_specificity', 0), epoch)

            # è®°å½•è¾…åŠ©ä»»åŠ¡çš„ç‹¬ç«‹éªŒè¯é›†å‡†ç¡®ç‡ (å¤„ç†DataParallelåŒ…è£…)
            model_mappings = model.module.mappings if isinstance(model, nn.DataParallel) else model.mappings
            for task in model_mappings.keys():
                if task == 'bom': continue
                verify_acc = periodic_verify_metrics.get(f'{task}_accuracy', 0)
                writer.add_scalar(f'Verify/{task.capitalize()}_Accuracy', verify_acc, epoch)

        # æ¨¡å‹ä¿å­˜å’Œæ—©åœ
        if current_auc > best_auc:
            best_auc = current_auc
            best_epoch = epoch + 1
            patience_counter = 0
            # è®°å½•æœ€ä½³epochä¿¡æ¯
            logger.log_best_epoch(epoch, train_metrics, val_metrics)
            # ä¿å­˜æ¨¡å‹æ—¶å¤„ç†DataParallelåŒ…è£…
            model_to_save = model.module if isinstance(model, nn.DataParallel) else model
            torch.save(model_to_save.state_dict(), os.path.join(output_dir, f'nodule_feature_cnn_{config["model_name"]}_best_auc.pth'))
            logger.log(f"  âœ… æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜ (AUC: {best_auc:.4f})")
        else:
            patience_counter += 1

        if patience_counter >= early_stop_patience:
            logger.log(f"ğŸ›‘ æ—©åœè§¦å‘ ({early_stop_patience}è½®æ— æ”¹å–„)!")
            break

    writer.close()
    logger.log(f"\nğŸ‰ V64 è®­ç»ƒå®Œæˆ!")
    logger.log(f"ğŸ† æœ€ä½³ BOM AUC: {best_auc:.4f}")

    # --- æœ€ç»ˆéªŒè¯ ---
    logger.log(f"\n\n--- æœ€ç»ˆæ¨¡å‹éªŒè¯ ---")
    logger.log(f"ğŸš€ å¯¹ç‹¬ç«‹éªŒè¯é›†è¿›è¡Œæœ€ç»ˆæ€§èƒ½è¯„ä¼°: {config['verify_data']}")

    # åŠ è½½æœ€ä½³æ¨¡å‹
    best_model_path = os.path.join(output_dir, f'nodule_feature_cnn_{config["model_name"]}_best_auc.pth')
    if os.path.exists(best_model_path):
        logger.log(f"  - Loading best model from: {best_model_path}")
        # åœ¨åŠ è½½state_dictå‰ï¼Œéœ€è¦å…ˆå®ä¾‹åŒ–ä¸€ä¸ªåŒæ ·ç»“æ„çš„æ¨¡å‹
        model_for_eval = MultiTaskNoduleCNN_V60(feature_mapping, dropout_rate=config['dropout_rate']).to(device)
        model_for_eval.load_state_dict(torch.load(best_model_path, map_location=device))

        logger.log(f"  - Verifying on {len(verify_dataset)} samples...")

        # éªŒè¯
        _, verify_metrics = validate_epoch(model_for_eval, verify_loader, loss_fn, device)

        # è®°å½•æœ€ç»ˆéªŒè¯ç»“æœ
        logger.log_final_verify(verify_metrics)

        logger.log("\n\n--- æœ€ç»ˆéªŒè¯æ€§èƒ½ ---")
        logger.log(f"  - æ•°æ®é›†: {config['verify_data']}")
        logger.log(f"  - æ ·æœ¬æ•°: {len(verify_dataset)}")
        logger.log("  --------------------")
        logger.log(f"  - BOM AUC:         {verify_metrics.get('bom_auc', 0):.4f}")
        logger.log(f"  - BOM Accuracy:    {verify_metrics.get('bom_accuracy', 0):.4f}")
        logger.log(f"  - BOM Sensitivity: {verify_metrics.get('bom_sensitivity', 0):.4f}")
        logger.log(f"  - BOM Specificity: {verify_metrics.get('bom_specificity', 0):.4f}")

        # æ‰“å°å…¶ä»–ä»»åŠ¡çš„å‡†ç¡®ç‡ (å¤„ç†DataParallelåŒ…è£…)
        final_model_mappings = model_for_eval.module.mappings if isinstance(model_for_eval, nn.DataParallel) else model_for_eval.mappings
        for task in sorted(final_model_mappings.keys()):
            if task == 'bom': continue
            acc = verify_metrics.get(f'{task}_accuracy', 0)
            logger.log(f"  - {task.capitalize():<12} Acc: {acc:.4f}")

        logger.log("  --------------------")
    else:
        logger.log(f"  - ğŸ”´ Error: Best model not found at {best_model_path}")

    logger.log(f"ğŸ“Š V64è®­ç»ƒç‰¹è‰²:")
    # è·å–å®é™…æ¨¡å‹å‚æ•°ï¼ˆå¤„ç†DataParallelåŒ…è£…ï¼‰
    actual_model = model.module if isinstance(model, nn.DataParallel) else model
    logger.log(f"  - EfficientNet-B0å¤šä»»åŠ¡æ¶æ„ ({sum(p.numel() for p in actual_model.parameters())/1e6:.2f}Må‚æ•°)")
    logger.log(f"  - 7ä¸ªåˆ†ç±»ä»»åŠ¡ (BOM, TI-RADS, 5ä¸ªå¾è±¡)")
    oof_desc = "è·³è¿‡OOFç­›é€‰" if config['OOF_p_true_threshold'] == 0 else f"OOF_p_true_threshold={config['OOF_p_true_threshold']}"
    logger.log(f"  - {oof_desc}, image_index_threshold={config['image_index_threshold']}")
    logger.log(f"  - å¤æ‚çš„äº”é‡æ•°æ®ç­›é€‰ç­–ç•¥")
    logger.log(f"  - åµŒå…¥ç‰¹å¾æ˜ å°„ä¾¿äºæ¨ç†")
    logger.log(f"ğŸ“ æ¨¡å‹è·¯å¾„: {best_model_path}")

    # ä¿å­˜è®­ç»ƒæ€»ç»“æŠ¥å‘Š
    logger.save_training_summary(config, best_auc, best_epoch)

if __name__ == "__main__":
    main()
