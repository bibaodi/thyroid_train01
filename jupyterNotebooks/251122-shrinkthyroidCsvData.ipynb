{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f06ba6df-dbbd-44d4-8788-ac303e30239d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success read with[utf-8]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def read_csv2pd(file_path, select_cols, newfilename=None):\n",
    "    encodings = ['utf-8', 'gbk', 'gb2312', 'latin1', 'cp1252']\n",
    "\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, usecols=select_cols, encoding=encoding)\n",
    "            print(f\"success read with[{encoding}]\")\n",
    "            if 0:\n",
    "                # 选择前50%的行\n",
    "                half_length = int(len(df) * 0.5)\n",
    "                df = df.iloc[:half_length]\n",
    "                # 随机选择50%的行（设置random_state以确保结果可重现）\n",
    "                df = df.sample(frac=0.01, random_state=34)\n",
    "            if newfilename:\n",
    "                df.to_csv(newfilename, index=False)\n",
    "            return df\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    \n",
    "def shrinkspreadSheetWithOrentation(spfile):\n",
    "    filefolder = os.path.dirname(spfile)\n",
    "    ori_file=os.path.basename(spfile)\n",
    "    newfilename='shrinked_'+ori_file\n",
    "\n",
    "\n",
    "    col_ori='orientation'\n",
    "    select_cols=['sop_uid','access_no','bom']\n",
    "    select_cols.append(col_ori)\n",
    "\n",
    "    os.chdir(filefolder)\n",
    "    all_data = read_csv2pd(ori_file, select_cols, 'select_'+ori_file)\n",
    "\n",
    "    all_data.loc[all_data[col_ori] == '纵切面', col_ori] = 'Lon'\n",
    "    all_data.loc[all_data[col_ori] == '横切面', col_ori] = 'Tra'\n",
    "    all_data.to_csv(newfilename, index=False)\n",
    "\n",
    "\n",
    "shrinkspreadSheetWithOrentation(r'/home/eton/job-trainThyUS/71-datasets/251016-efficientNetDatas/21-candidate_table/none_single_tr13_with_orientation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eef507e-f802-4e06-8df3-e9523f529a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder=r'/home/eton/job-trainThyUS/71-datasets/251016-efficientNetDatas/21-candidate_table/v6/all_matched_sop_v6'\n",
    "ori_file='all_matched_sop_v6.csv'\n",
    "newfilename='shrinked_all_matched_sop_v6.csv'\n",
    "\n",
    "col_ori='orientation'\n",
    "select_cols=['sop_uid','access_no','bom']\n",
    "select_cols.append(col_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ea9b37f-935f-4c3d-bf4f-f478db66707d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sop_uid\n",
      "access_no\n",
      "nindex\n",
      "exam_no\n",
      "p_index\n",
      "bom\n",
      "bethesda\n",
      "utype\n",
      "position\n",
      "anatomy\n",
      "vertical\n",
      "sagittal\n",
      "center\n",
      "size\n",
      "sizes\n",
      "max_size\n",
      "composition\n",
      "echo\n",
      "shape\n",
      "margin\n",
      "ratio\n",
      "foci\n",
      "ti_rads\n",
      "ti_rads_str\n",
      "cdfi\n",
      "description\n",
      "impression\n",
      "nodule_count\n",
      "left_nodule_count\n",
      "right_nodule_count\n",
      "p_nodule_count\n",
      "p_left_nodule_count\n",
      "p_right_nodule_count\n",
      "bethesda_str\n",
      "cancer\n",
      "gene\n",
      "category\n",
      "p_category\n",
      "exam_time\n",
      "p_exam_time\n",
      "flag\n",
      "p_position\n",
      "p_description\n",
      "p_impression\n",
      "match_size_count\n",
      "side_single\n",
      "follicle\n",
      "inflammation\n",
      "orientation\n"
     ]
    }
   ],
   "source": [
    "all_cols='sop_uid,access_no,nindex,exam_no,p_index,bom,bethesda,utype,position,anatomy,vertical,sagittal,center,size,sizes,max_size,composition,echo,shape,margin,ratio,foci,ti_rads,ti_rads_str,cdfi,description,impression,nodule_count,left_nodule_count,right_nodule_count,p_nodule_count,p_left_nodule_count,p_right_nodule_count,bethesda_str,cancer,gene,category,p_category,exam_time,p_exam_time,flag,p_position,p_description,p_impression,match_size_count,side_single,follicle,inflammation,orientation'\n",
    "for icol in all_cols.split(','):\n",
    "    print(icol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59cdcd46-bebf-49f8-9b99-e3c86d79a32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63e9c247-bcf6-4303-99e9-d1a0e17814e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_matched_sop_v6.csv\tall_matched_sop_v6_readme.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf729007-59e0-4936-b821-e0ca43929450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7189b18-9b5e-4e4d-b5d4-899f8f9f6f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success read with[gbk]\n"
     ]
    }
   ],
   "source": [
    "def read_csv2pd(file_path, newfilename=None):\n",
    "    encodings = ['utf-8', 'gbk', 'gb2312', 'latin1', 'cp1252']\n",
    "\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, usecols=select_cols, encoding=encoding)\n",
    "            print(f\"success read with[{encoding}]\")\n",
    "            if 0:\n",
    "                # 选择前50%的行\n",
    "                half_length = int(len(df) * 0.5)\n",
    "                df = df.iloc[:half_length]\n",
    "                # 随机选择50%的行（设置random_state以确保结果可重现）\n",
    "                df = df.sample(frac=0.01, random_state=34)\n",
    "            if newfilename:\n",
    "                df.to_csv(newfilename, index=False)\n",
    "            return df\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "\n",
    "\n",
    "all_data = read_csv2pd(ori_file, newfilename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "447de863-4bf0-407d-9873-519ced43391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.loc[all_data[col_ori] == '纵切面', col_ori] = 'Lon'\n",
    "all_data.loc[all_data[col_ori] == '横切面', col_ori] = 'Tra'\n",
    "all_data.to_csv('2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2af3d5d1-4138-493a-84e0-f7928a34e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果您的列中可能包含除'AB'和'CD'之外的其他值，使用map()方法会将这些未映射的值转换为NaN。\n",
    "# 而replace()方法只会替换指定的值，保留其他值不变。\n",
    "if 0:\n",
    "    # 这样不会修改原始的df，而是返回一个新的Series\n",
    "    new_series = df['column_name'].replace({'AB': 0, 'CD': 1})\n",
    "    # 要修改原始数据框，需要重新赋值\n",
    "    df['column_name'] = df['column_name'].replace({'AB': 0, 'CD': 1})\n",
    "if 0:\n",
    "    # 同样不会原地修改\n",
    "    new_series = df['column_name'].map({'AB': 0, 'CD': 1})\n",
    "\n",
    "    df['column_name'] = df['column_name'].map({'AB': 0, 'CD': 1})\n",
    "if 0:\n",
    "    mapping = {'AB': 0, 'CD': 1}\n",
    "    df.replace({'column_name': mapping}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c01c6-133b-4ff0-a8ac-83731c0650da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
